\section{Podsumowanie}

Wczesne wprowadzenie ujednoliconego standardu, jakim jest MPI przysporzyło mu popularności na tle rosnącego zapotrzebowania i rozwoju na obliczenia równoległe. Obszerna dokumentacja oraz mnogość implementacji zarówno pod kątem języków programowania jak i architektury procesorów sprawiła, że MPI stał się często stosowanym rozwiązaniem w systemach rozproszonych. Dodatkowymi zaletami przemiawiającymi za biblioteką jest hermetyczny interfejs programistyczny, sprawiający że program uruchomiony na różnych maszynach działa identycznie. Biblioteka MPI udostępnia kilka odmiennych sposobów komunikacji, pozostawiając osobie piszącej kod prawo wyboru, którą wersję zaimplementować. W mniejszych systemach (np. komputer z pojedynczym procesorem wielordzeniowym) zazwyczaj wygodniejszym sposobem jest komunikacja typu punk-punkt przy pomocy funkcji MPI\textunderscore Receive i MPI\textunderscore Send --- zarządzanie na poziomie pojedynczego kanału komunikacyjnego ułatwia modyfikację algorytmu. W przypadku dużej liczby procesów, wygodniejszym sposobem jest komunikacja kolektywna.

Pomimo dużej elastyczności udostepnianej przez interfejs MPI, należy pamiętać, aby w miarę możliwości komunikacji między procesami. Z każdą wymianą wiadomości związany jest narzut czasowy, zazwyczaj znacznie większy od operacji podstawowych. W przypadku gdy inicjalizowana jest wymiana informacji ze wszystkimi procesami przy użyciu funkcji \texttt{MPI\textunderscore Send}, proces źródłowy musi wykonać p - 1 instrukcji, gdzie p oznacza całkowitą liczbę procesów (należy pamiętać, że w przypadku dużych systemów może to oznaczać tysiące czasochłonnych operacji). Złożoność obliczeniowa takiego przedsięwzięcia jest rzędu $\mathcal{O}(p)$ (przy pominięciu n liczby danych i operacji na nich wykonywanych). W praktyce to oznacza, że wraz ze wzrostem liczby dostępnych procesów p program będzie przyspieszał do pewnej wartości granicznej P, po której znacznie zwalniać (narzut czasowy związany z komunikacja zacznie przeważać nad przyspieszeniem związanym ze zrównolegleniem programu). Dużo lepszym sposobem jest wykorzystanie komunikacji przez rozgłaszanie, w którym udział biorą wszystkie procesy przez cały czas trwania wymiany wiadomości. Nie eliminuje on całkowicie problemu związanego z rosnącym narzutem czasowym przy zwiększonej liczbie procesorów, ale sprawia że jest on mniejszy (rzędu $\mathcal{O}(logp)$). Alternatywną opcją służącą zmniejszającą narzut czasowy komunikacji jest zastosowanie obliczeń nadmiarowych (zwanych też redundantnymi). Są to operacje powtarzające się w wielu procesach, a dające ten sam wynik -- czasami opłaca się wielokrotnie policzyć tę samą wartość w różnych procesach zamiast wykonać obliczenia w pojedynczym korzeniu, a nastęnie rozesłać do reszty (zwłaszcza, gdy są to nieskomplikowane obliczenia). 